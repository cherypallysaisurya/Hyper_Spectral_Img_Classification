# -*- coding: utf-8 -*-
"""hsi_exp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GcDzadE4XR6frJj7JMNeENXCE-vgR56V

###1. Imports & Dataset Loader
"""

import numpy as np, torch, torch.nn as nn, torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import accuracy_score, confusion_matrix, cohen_kappa_score
import matplotlib.pyplot as plt
from scipy.io import loadmat
import os

def download_dataset():
    urls = {
        "Indian_pines_corrected.mat": "https://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat",
        "Indian_pines_gt.mat": "https://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat"
    }
    for f, u in urls.items():
        if not os.path.exists(f):
            os.system(f"wget -q " + u + " -O " + f)
download_dataset()

data = loadmat("Indian_pines_corrected.mat")["indian_pines_corrected"]
gt = loadmat("Indian_pines_gt.mat")["indian_pines_gt"]

print("Data:", data.shape, "| Ground Truth:", gt.shape)

"""###2. Visualization"""

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(data[:, :, 100], cmap="viridis")
plt.title("Band 100")

plt.subplot(1, 2, 2)
plt.imshow(gt, cmap="nipy_spectral")
plt.title("Ground Truth")
plt.tight_layout()
plt.show()

"""###3. Class-Balanced Patch Extraction"""

def prepare_balanced_data(data, gt, patch=15, per_class=200):
    h, w, c = data.shape
    pad = patch // 2
    padded = np.pad(data, ((pad,pad),(pad,pad),(0,0)), mode='reflect')
    X, Y = [], []
    for cl in np.unique(gt)[1:]:
        indices = np.argwhere(gt == cl)
        np.random.shuffle(indices)
        for y, x in indices[:per_class]:
            patch_data = padded[y:y+patch, x:x+patch, :]
            X.append(np.transpose(patch_data, (2, 0, 1)))
            Y.append(cl - 1)
    X, Y = np.array(X), np.array(Y)
    idx = np.arange(len(Y)); np.random.shuffle(idx)
    n = len(Y); n_train, n_val = int(0.7*n), int(0.15*n)
    return X[idx[:n_train]], Y[idx[:n_train]], X[idx[n_train:n_train+n_val]], Y[idx[n_train:n_train+n_val]], X[idx[n_train+n_val:]], Y[idx[n_train+n_val:]]

train_x, train_y, val_x, val_y, test_x, test_y = prepare_balanced_data(data, gt)

"""### 4. ResNet Block"""

class ResBlock(nn.Module):
    def __init__(self, in_c, out_c):
        super().__init__()
        self.block = nn.Sequential(
            nn.Conv2d(in_c, out_c, 3, padding=1),
            nn.BatchNorm2d(out_c),
            nn.ReLU(),
            nn.Conv2d(out_c, out_c, 3, padding=1),
            nn.BatchNorm2d(out_c)
        )
        self.skip = nn.Conv2d(in_c, out_c, 1) if in_c != out_c else nn.Identity()
        self.relu = nn.ReLU()

    def forward(self, x):
        return self.relu(self.block(x) + self.skip(x))

"""###5. CNN + Dense Transformer Model"""

class ResNetFeat(nn.Module):
    def __init__(self, in_c):
        super().__init__()
        self.net = nn.Sequential(
            ResBlock(in_c, 64),
            nn.MaxPool2d(2),
            ResBlock(64, 128),
            nn.AdaptiveAvgPool2d((1, 1))
        )

    def forward(self, x):
        return self.net(x).view(x.size(0), -1)

class MultiHeadAttention(nn.Module):
    def __init__(self, d_model, heads):
        super().__init__()
        self.h = heads
        self.d = d_model // heads
        self.qkv = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(3)])
        self.out = nn.Linear(d_model, d_model)

    def split(self, x, b):
        return x.view(b, -1, self.h, self.d).permute(0, 2, 1, 3)

    def forward(self, q, k, v):
        B = q.size(0)
        q, k, v = [self.split(l(x), B) for l, x in zip(self.qkv, [q, k, v])]
        scores = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(self.d)
        attn = torch.softmax(scores, dim=-1)
        x = torch.matmul(attn, v).permute(0, 2, 1, 3).reshape(B, -1, self.h * self.d)
        return self.out(x)

class EncoderLayer(nn.Module):
    def __init__(self, d_model, heads, d_ff):
        super().__init__()
        self.attn = MultiHeadAttention(d_model, heads)
        self.ff = nn.Sequential(nn.Linear(d_model, d_ff), nn.GELU(), nn.Linear(d_ff, d_model))
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)

    def forward(self, x):
        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))
        return x + self.ff(self.norm2(x))

class DenseTransformer(nn.Module):
    def __init__(self, d_model, heads, layers, d_ff, seq_len):
        super().__init__()
        self.pos = nn.Parameter(torch.zeros(1, seq_len, d_model))
        self.enc = nn.ModuleList([EncoderLayer(d_model, heads, d_ff) for _ in range(layers)])
        self.norm = nn.LayerNorm(d_model)

    def forward(self, x):
        x = x + self.pos
        for layer in self.enc:
            x = layer(x)
        return self.norm(x)

class HybridModel(nn.Module):
    def __init__(self, in_channels, num_classes):
        super().__init__()
        self.encoder = ResNetFeat(in_channels)
        self.trans = DenseTransformer(128, 4, 2, 256, 1)
        self.head = nn.Sequential(nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, num_classes))

    def forward(self, x):
        feat = self.encoder(x).unsqueeze(1)
        return self.head(self.trans(feat)[:, 0, :])

"""### 6. Label Smoothing & Training Loop"""

def label_smoothing(preds, y, eps=0.1):
    n = preds.size(1)
    with torch.no_grad():
        y_onehot = torch.zeros_like(preds).scatter(1, y.unsqueeze(1), 1)
        y_onehot = y_onehot * (1 - eps) + eps / n
    return -(y_onehot * F.log_softmax(preds, dim=1)).sum(dim=1).mean()

def train_model(model, train_x, train_y, val_x, val_y, epochs=60):
    dev = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(dev)
    opt = torch.optim.Adam(model.parameters(), lr=0.001)

    train_loader = DataLoader(TensorDataset(torch.Tensor(train_x), torch.LongTensor(train_y)), batch_size=64, shuffle=True)
    val_loader = DataLoader(TensorDataset(torch.Tensor(val_x), torch.LongTensor(val_y)), batch_size=64)

    trL, trA, valL, valA = [], [], [], []

    for ep in range(epochs):
        model.train()
        total_loss, correct = 0, 0
        for xb, yb in train_loader:
            xb, yb = xb.to(dev), yb.to(dev)
            opt.zero_grad()
            preds = model(xb)
            loss = label_smoothing(preds, yb)
            loss.backward()
            opt.step()
            total_loss += loss.item()
            correct += (preds.argmax(1) == yb).sum().item()
        trL.append(total_loss / len(train_loader))
        trA.append(correct / len(train_loader.dataset))

        model.eval()
        val_loss, val_correct = 0, 0
        with torch.no_grad():
            for xb, yb in val_loader:
                xb, yb = xb.to(dev), yb.to(dev)
                preds = model(xb)
                val_loss += F.cross_entropy(preds, yb).item()
                val_correct += (preds.argmax(1) == yb).sum().item()
        valL.append(val_loss / len(val_loader))
        valA.append(val_correct / len(val_loader.dataset))

        print(f"[{ep+1}] Train Loss: {trL[-1]:.3f} (â–²{trA[-1]*100:.2f}%) | Val Loss: {valL[-1]:.3f} (â–²{valA[-1]*100:.2f}%)")

    # ðŸ“ˆ Final Plots
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(trL, label="Train", color='blue')
    plt.plot(valL, label="Val", color='orange')
    plt.title("Loss", fontsize=14)
    plt.xlabel("Epochs", fontsize=12)
    plt.ylabel("Loss", fontsize=12)
    plt.grid(True)
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(trA, label="Train", color='blue')
    plt.plot(valA, label="Val", color='orange')
    plt.title("Accuracy", fontsize=14)
    plt.xlabel("Epochs", fontsize=12)
    plt.ylabel("Accuracy", fontsize=12)
    plt.grid(True)
    plt.legend()

    plt.suptitle("Training & Validation Performance", fontsize=16)
    plt.tight_layout()
    plt.show()

"""###7. Run Training"""

model = HybridModel(data.shape[2], len(np.unique(gt)) - 1)
train_model(model, train_x, train_y, val_x, val_y)

"""### 8. Evaluation Metrics (OA, AA, Kappa, Confusion Matrix)"""

def evaluate_model(model, test_x, test_y):
    dev = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(dev); model.eval()
    test_loader = DataLoader(TensorDataset(torch.Tensor(test_x), torch.LongTensor(test_y)), batch_size=64)

    all_preds, all_labels = [], []
    with torch.no_grad():
        for xb, yb in test_loader:
            xb, yb = xb.to(dev), yb.to(dev)
            preds = model(xb).argmax(1).cpu().numpy()
            all_preds.extend(preds)
            all_labels.extend(yb.cpu().numpy())

    all_preds, all_labels = np.array(all_preds), np.array(all_labels)
    oa = accuracy_score(all_labels, all_preds)
    cm = confusion_matrix(all_labels, all_preds)
    kappa = cohen_kappa_score(all_labels, all_preds)
    aa = np.mean(cm.diagonal() / cm.sum(axis=1))

    print("\nðŸ“Š Evaluation Metrics:")
    print(f"âœ… Overall Accuracy (OA): {oa*100:.2f}%")
    print(f"âœ… Average Accuracy (AA): {aa*100:.2f}%")
    print(f"âœ… Kappa Coefficient: {kappa:.4f}")

    # Confusion matrix heatmap
    plt.figure(figsize=(6, 5))
    plt.imshow(cm, cmap="Blues")
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted"); plt.ylabel("True")
    plt.colorbar(); plt.tight_layout(); plt.show()

"""### 9. Full-Image Prediction (Pixel-wise Inference)"""

def predict_full_image(model, data, gt, patch_size=15):
    h, w, c = data.shape
    pad = patch_size // 2
    padded = np.pad(data, ((pad,pad),(pad,pad),(0,0)), mode='reflect')
    prediction_map = np.zeros((h, w), dtype=int)
    dev = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(dev); model.eval()

    with torch.no_grad():
        for i in range(h):
            for j in range(w):
                if gt[i, j] == 0:
                    continue
                patch = padded[i:i+patch_size, j:j+patch_size, :]
                patch = np.transpose(patch, (2, 0, 1))
                patch_tensor = torch.Tensor(patch).unsqueeze(0).to(dev)
                pred = model(patch_tensor).argmax(1).cpu().item()
                prediction_map[i, j] = pred + 1
    return prediction_map

"""###10. Visualize Ground Truth vs Predicted Map"""

pred_map = predict_full_image(model, data, gt)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.imshow(gt, cmap='nipy_spectral')
plt.title("Ground Truth")

plt.subplot(1, 2, 2)
plt.imshow(pred_map, cmap='nipy_spectral')
plt.title("Predicted Map")

plt.tight_layout()
plt.show()

"""### Final Step: Evaluate"""

evaluate_model(model, test_x, test_y)

